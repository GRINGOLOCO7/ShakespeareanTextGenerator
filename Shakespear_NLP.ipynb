{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gregorio Orlando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed for the project\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.corpus import shakespeare\n",
    "import xml.etree.ElementTree as ET\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a text file containing Shakespeare's works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a_and_c.xml',\n",
       " 'dream.xml',\n",
       " 'hamlet.xml',\n",
       " 'j_caesar.xml',\n",
       " 'macbeth.xml',\n",
       " 'merchant.xml',\n",
       " 'othello.xml',\n",
       " 'r_and_j.xml']"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all the shakespeare books in nltk corpus\n",
    "shakespeare.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll chose: HAMLET. The famus play of the \"to be or not to be\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'PLAY' at 0x000001A51D397100>"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the hamlet book\n",
    "play = shakespeare.xml('hamlet.xml')\n",
    "play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the addres of the root of the play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: The Tragedy of Hamlet, Prince of Denmark\n"
     ]
    }
   ],
   "source": [
    "# print title of the book\n",
    "print('%s: %s' % (play[0].tag, play[0].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. parse the XML and extract the relevant text elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recursively extract text from XML elements\n",
    "def extract_text(element): # element is an XML element\n",
    "    text = element.text or \"\" # initialize text with element's text\n",
    "    for child in element: # loop over element's children\n",
    "        text += extract_text(child) # recursively extract text from child\n",
    "        if child.tail: # if child has a tail\n",
    "            text += child.tail # add the tail to text\n",
    "    return text # return the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print the text\n",
    "play_text = extract_text(play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179465"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(play_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(play_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' son to the late, and nephew to the present king.\\n'"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_text[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To be, or not to be'"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for the \"To be, or not to be\" soliloquy\n",
    "to_be_text = \"To be, or not to be\"\n",
    "start_index = play_text.find(to_be_text)\n",
    "end_index = start_index + len(to_be_text)\n",
    "play_text[start_index:end_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. convert it to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to be, or not to be'"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_text_lower = play_text.lower()\n",
    "play_text_lower[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(play_text_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. splitting it into tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39514"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use 'word_tokenize' to tokenize the play text\n",
    "# meaning splitting the text into words\n",
    "play_tokenized = word_tokenize(play_text_lower)\n",
    "len(play_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gertrude',\n",
       " ',',\n",
       " 'queen',\n",
       " 'of',\n",
       " 'denmark',\n",
       " ',',\n",
       " 'and',\n",
       " 'mother',\n",
       " 'to',\n",
       " 'hamlet']"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_tokenized[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. removing punctuation & tokenize again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['denmark',\n",
       " 'hamlet',\n",
       " 'act',\n",
       " 'i',\n",
       " 'scene',\n",
       " 'i',\n",
       " 'elsinore',\n",
       " 'a',\n",
       " 'platform',\n",
       " 'before']"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use 'RegexpTokenizer' to tokenize the play text again and remove punctuation\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "play_words = tokenizer.tokenize(play_text_lower)\n",
    "play_words[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(play_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case folding and creating vocabulary\n",
    "vocab = set(play_words)  # Set of unique words in play_words\n",
    "\n",
    "# Initialize bigrams dictionary\n",
    "# Each key is a bigram (two consecutive words), and the value is a dictionary:\n",
    "#   - \"occurrence\": Total count of how many times this bigram appears\n",
    "#   - \"next_words\": Dictionary of words that follow this bigram with their counts\n",
    "bigrams = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding through the corpus to get bigram and next-word counts\n",
    "for i in range(len(play_words) - 2):  # Iterates through play_words to extract bigrams\n",
    "    bigram = (play_words[i], play_words[i + 1])  # Current bigram\n",
    "    next_word = play_words[i + 2]  # Word that follows the bigram\n",
    "\n",
    "    # Update bigram counts\n",
    "    if bigram not in bigrams:\n",
    "        bigrams[bigram] = {\n",
    "            \"occurrence\": 1,  # Initialize occurrence count\n",
    "            \"next_words\": {next_word: 1}  # Initialize next-word dictionary\n",
    "        }\n",
    "    else:\n",
    "        bigrams[bigram][\"occurrence\"] += 1  # Increment occurrence count\n",
    "\n",
    "        # Update next-word counts\n",
    "        if next_word in bigrams[bigram][\"next_words\"]:\n",
    "            bigrams[bigram][\"next_words\"][next_word] += 1\n",
    "        else:\n",
    "            bigrams[bigram][\"next_words\"][next_word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'tragedy'): {'occurrence': 1, 'next_words': {'of': 1}}\n",
      "('tragedy', 'of'): {'occurrence': 1, 'next_words': {'hamlet': 1}}\n",
      "('of', 'hamlet'): {'occurrence': 8, 'next_words': {'prince': 1, 's': 4, 'our': 1, 'sits': 1, 'do': 1}}\n"
     ]
    }
   ],
   "source": [
    "example_bigrams = list(bigrams.items())[:3]  # Show only the first 3 bigrams\n",
    "for bigram, details in example_bigrams:\n",
    "    print(f\"{bigram}: {details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Count for bigram ('to', 'be') is: {'occurrence': 34, 'next_words': {'done': 1, 'contracted': 1, 'disjoint': 1, 'near': 1, 'commanded': 1, 'a': 3, 'nothing': 1, 'honest': 1, 'one': 1, 'sounded': 1, 'or': 1, 'that': 1, 'wish': 1, 'considered': 1, 'played': 1, 'forestalled': 1, 'free': 1, 'too': 1, 'bless': 1, 'kind': 1, 'demanded': 1, 'last': 1, 'great': 1, 'spilt': 1, 'your': 1, 'heard': 1, 'buried': 2, 'made': 2, 'in': 1, 'damn': 1}}\n",
      "Example: Count for bigram ('be', 'or') is: {'occurrence': 1, 'next_words': {'not': 1}}\n",
      "Example: Count for bigram ('airplane', 'house') is: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Example: Count for bigram ('to', 'be') is: {bigrams.get(('to', 'be'))}\")\n",
    "print(f\"Example: Count for bigram ('be', 'or') is: {bigrams.get(('be', 'or'))}\")\n",
    "print(f\"Example: Count for bigram ('airplane', 'house') is: {bigrams.get(('airplane', 'house'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this rappresentation I am able to have all the bigrams (set of 2 consecutive words), with their occurence. Plus the occurence of each word that came after the bigram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Bigram Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function shows me the possible next words that I can have after the given gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_bigram_to_next_token_counts(gram, grams):\n",
    "    #print(f\"\\nInput bigram: {bigram}\")\n",
    "\n",
    "    # Check if the bigram exists in the dictionary\n",
    "    if gram not in grams:\n",
    "        print(\"No suggestions available for this bigram.\")\n",
    "        return []\n",
    "\n",
    "    # Access the next-word counts for the given bigram\n",
    "    next_word_counts = grams[gram][\"next_words\"]\n",
    "\n",
    "    # Sort and return the top 3 suggestions (words with the highest counts)\n",
    "    top_suggestions = sorted(next_word_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    return top_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top suggestions: [('a', 3), ('buried', 2), ('made', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "tokens = ('to', 'be')\n",
    "top_suggestions = from_bigram_to_next_token_counts(tokens, bigrams)\n",
    "print(f\"Top suggestions: {top_suggestions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top suggestions: [('not', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "tokens = ('be', 'or')\n",
    "top_suggestions = from_bigram_to_next_token_counts(tokens, bigrams)\n",
    "print(f\"Top suggestions: {top_suggestions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after 'to', 'be' we can have [('a', 3), ('buried', 2), ('made', 2), ..] this means that after 'to be' the most commun word to occur is 'a'\n",
    "\n",
    "On the other hand after 'be or' there is only one word to occur with 100% probability, that is 'not'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the gram and the possible next words, we can calculate the probability of occurence of each possible word after the given gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_bigram_to_next_token_probs(gram, grams):\n",
    "    #print(f\"\\nInput bigram: {bigram}\")\n",
    "\n",
    "    # Check if the bigram exists in the dictionary\n",
    "    if gram not in grams:\n",
    "        print(\"No suggestions available for this bigram.\")\n",
    "        return []\n",
    "\n",
    "    # Access the next-word counts for the given bigram\n",
    "    next_word_counts = grams[gram][\"next_words\"]\n",
    "\n",
    "    # Sort and return the top 3 suggestions (words with the highest counts)\n",
    "    top_suggestions = sorted(next_word_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "    # Calculate the total count of next words\n",
    "    total_count = sum(next_word_counts.values())\n",
    "\n",
    "    # Calculate the probabilities for each suggestion\n",
    "    top_suggestions_probs = [(word, count / total_count) for word, count in top_suggestions] # Calculate the probabilities as count/total_count\n",
    "    result = [total_count, top_suggestions_probs]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top suggestions for token: ('to', 'be')\n",
      "are: [('a', 0.08823529411764706), ('buried', 0.058823529411764705), ('made', 0.058823529411764705)]\n",
      "With total number of possible words after the bigram of 34\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "tokens = ('to', 'be')\n",
    "top_suggestions = from_bigram_to_next_token_probs(tokens, bigrams)\n",
    "print(f\"Top suggestions for token: {tokens}\\nare: {top_suggestions[1]}\\nWith total number of possible words after the bigram of {top_suggestions[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top suggestions for token: ('be', 'or')\n",
      "are: [('not', 1.0)]\n",
      "With total number of possible words after the bigram of 1\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "tokens = ('be', 'or')\n",
    "top_suggestions = from_bigram_to_next_token_probs(tokens, bigrams)\n",
    "print(f\"Top suggestions for token: {tokens}\\nare: {top_suggestions[1]}\\nWith total number of possible words after the bigram of {top_suggestions[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing as before, but now we have a probability and not a number of time it occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Next Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will pick with weighted random choice the next word. This means that even if after 'to be' the most tipical word to appear is 'a', we still give space to the algorithm to might chose something else. This is why our bigram can be less accurate than quadgram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next_token(bigram, bigrams):\n",
    "    # Get the probabilities for the next tokens\n",
    "    total_count, next_token_probs = from_bigram_to_next_token_probs(bigram, bigrams)\n",
    "    # If no next tokens are available, return None\n",
    "    if total_count == 0 or not next_token_probs:\n",
    "        return None\n",
    "    # Extract tokens and their probabilities\n",
    "    tokens = [token for token, prob in next_token_probs]\n",
    "    probabilities = [prob for token, prob in next_token_probs]\n",
    "    # Sample a token based on the probabilities\n",
    "    next_token = random.choices(tokens, weights=probabilities, k=1)[0]  # Sample one token\n",
    "    return next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled next token for bigram ('to', 'be'): buried\n"
     ]
    }
   ],
   "source": [
    "tokens = ('to', 'be')\n",
    "next_token = sample_next_token(tokens, bigrams)\n",
    "print(f\"Sampled next token for bigram {tokens}: {next_token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have never used weighted sampling, so I wanted to be sure that the occurence of the best word reflect the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling results after 1000 iterations:\n",
      "made: 276 times (probability ~ 0.2760)\n",
      "a: 444 times (probability ~ 0.4440)\n",
      "buried: 280 times (probability ~ 0.2800)\n"
     ]
    }
   ],
   "source": [
    "# Test weighted sampling\n",
    "from collections import Counter\n",
    "\n",
    "tokens = ('to', 'be')\n",
    "results = []\n",
    "\n",
    "# Run the sampling 1000 times\n",
    "for _ in range(1000):\n",
    "    next_token = sample_next_token(tokens, bigrams)\n",
    "    results.append(next_token)\n",
    "\n",
    "# Count occurrences of each word\n",
    "occurrences = Counter(results)\n",
    "print(\"Sampling results after 1000 iterations:\")\n",
    "for word, count in occurrences.items():\n",
    "    print(f\"{word}: {count} times (probability ~ {count / 1000:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weitghted random choice is working quite good, as expected it mostly give us the one with higher probability, but not always!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will take the gram, calculate the next word to occur, create a new gram with the new generated word and repeat the process. Doing so we expect to recreate the famus passeges of the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_from_bigram(gram, grams, max_length=100):\n",
    "    # Initialize the generated text with the bigram\n",
    "    generated_text = list(gram)\n",
    "    # Generate the next tokens until reaching the maximum length\n",
    "    for _ in range(max_length):\n",
    "        # Sample the next token\n",
    "        next_token = sample_next_token(gram, grams)\n",
    "        # If no next token is available, stop the generation\n",
    "        if next_token is None:\n",
    "            break\n",
    "        # Append the token to the generated text\n",
    "        generated_text.append(next_token)\n",
    "        # Update the bigram for the next iteration\n",
    "        gram = (gram[1:] + (next_token,))\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text from bigram ('to', 'be'):\n",
      "to be buried quick with her gentleman she speaks much of water hast thou been a gentlewoman she should have fatted all the holy vows of heaven visit her face too roughly heaven and earth must i remember why she even she o god a mercy lord polonius what is the poison into the grave to tell the secrets of my father horatio where my abridgement comes enter four or five players you are not sterling tender yourself more dearly or not at all that suffers nothing a man as hamlet is a man take him for a certain term to walk\n"
     ]
    }
   ],
   "source": [
    "tokens = ('to', 'be')\n",
    "generated_text = generate_text_from_bigram(tokens, bigrams)\n",
    "print(f\"Generated text from bigram {tokens}:\\n{' '.join(generated_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text from bigram ('be', 'or'):\n",
      "be or not at all i would not hear your enemy say so nor shall you see there is a man might play but i thank you sir exit rosencrantz wilt please you to drink deep ere you go your servants tend laertes farewell ophelia o help him you sweet heavens hamlet if thou hast uphoarded in thy memory see thou character give thy thoughts no tongue nor any unproportioned thought his act be thou a spirit of health or goblin damn d and so without more circumstance at all that he is the matter my mother had not borne me i\n"
     ]
    }
   ],
   "source": [
    "tokens = ('be', 'or')\n",
    "generated_text = generate_text_from_bigram(tokens, bigrams)\n",
    "print(f\"Generated text from bigram {tokens}:\\n{' '.join(generated_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Different N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = {}\n",
    "# Sliding through the corpus to get trigrams and next-word counts\n",
    "for i in range(len(play_words) - 3):  # Iterates through play_words to extract trigrams\n",
    "    trigram = (play_words[i], play_words[i + 1], play_words[i+2])  # Current trigrams\n",
    "    next_word = play_words[i + 3]  # Word that follows the trigrams\n",
    "\n",
    "    # Update trigrams counts\n",
    "    if trigram not in trigrams:\n",
    "        trigrams[trigram] = {\n",
    "            \"occurrence\": 1,  # Initialize occurrence count\n",
    "            \"next_words\": {next_word: 1}  # Initialize next-word dictionary\n",
    "        }\n",
    "    else:\n",
    "        trigrams[trigram][\"occurrence\"] += 1  # Increment occurrence count\n",
    "\n",
    "        # Update next-word counts\n",
    "        if next_word in trigrams[trigram][\"next_words\"]:\n",
    "            trigrams[trigram][\"next_words\"][next_word] += 1\n",
    "        else:\n",
    "            trigrams[trigram][\"next_words\"][next_word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'tragedy', 'of'): {'occurrence': 1, 'next_words': {'hamlet': 1}}\n",
      "('tragedy', 'of', 'hamlet'): {'occurrence': 1, 'next_words': {'prince': 1}}\n",
      "('of', 'hamlet', 'prince'): {'occurrence': 1, 'next_words': {'of': 1}}\n"
     ]
    }
   ],
   "source": [
    "example_trigrams = list(trigrams.items())[:3]  # Show only the first 3 trigrams\n",
    "for trigram, details in example_trigrams:\n",
    "    print(f\"{trigram}: {details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Count for bigram ('to', 'be', 'or') is: {'occurrence': 1, 'next_words': {'not': 1}}\n",
      "Example: Count for bigram ('airplane', 'house', 'car') is: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Example: Count for bigram ('to', 'be', 'or') is: {trigrams.get(('to', 'be', 'or'))}\")\n",
    "print(f\"Example: Count for bigram ('airplane', 'house', 'car') is: {trigrams.get(('airplane', 'house', 'car'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ('to', 'be', 'or')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top suggestions: [('not', 1)]\n"
     ]
    }
   ],
   "source": [
    "top_suggestions = from_bigram_to_next_token_counts(tokens, trigrams)\n",
    "print(f\"Top suggestions: {top_suggestions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top suggestions for token: ('to', 'be', 'or')\n",
      "are: [('not', 1.0)]\n",
      "With total number of possible words after the bigram of 1\n"
     ]
    }
   ],
   "source": [
    "top_suggestions = from_bigram_to_next_token_probs(tokens, trigrams)\n",
    "print(f\"Top suggestions for token: {tokens}\\nare: {top_suggestions[1]}\\nWith total number of possible words after the bigram of {top_suggestions[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled next token for bigram ('to', 'be', 'or'): not\n"
     ]
    }
   ],
   "source": [
    "next_token = sample_next_token(tokens, trigrams)\n",
    "print(f\"Sampled next token for bigram {tokens}: {next_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text from bigram ('to', 'be', 'or'):\n",
      "to be or not to crack the wind of me as if you\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text_from_bigram(tokens, trigrams, max_length=10)\n",
    "print(f\"Generated text from bigram {tokens}:\\n{' '.join(generated_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadgrams = {}\n",
    "# Sliding through the corpus to get quadgrams and next-word counts\n",
    "for i in range(len(play_words) - 4):  # Iterates through play_words to extract quadgrams\n",
    "    quadgram = (play_words[i], play_words[i + 1], play_words[i+2], play_words[i+3])  # Current quadgrams\n",
    "    next_word = play_words[i + 4]  # Word that follows the quadgrams\n",
    "\n",
    "    # Update quadgrams counts\n",
    "    if quadgram not in quadgrams:\n",
    "        quadgrams[quadgram] = {\n",
    "            \"occurrence\": 1,  # Initialize occurrence count\n",
    "            \"next_words\": {next_word: 1}  # Initialize next-word dictionary\n",
    "        }\n",
    "    else:\n",
    "        quadgrams[quadgram][\"occurrence\"] += 1  # Increment occurrence count\n",
    "\n",
    "        # Update next-word counts\n",
    "        if next_word in quadgrams[quadgram][\"next_words\"]:\n",
    "            quadgrams[quadgram][\"next_words\"][next_word] += 1\n",
    "        else:\n",
    "            quadgrams[quadgram][\"next_words\"][next_word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'tragedy', 'of', 'hamlet'): {'occurrence': 1, 'next_words': {'prince': 1}}\n",
      "('tragedy', 'of', 'hamlet', 'prince'): {'occurrence': 1, 'next_words': {'of': 1}}\n",
      "('of', 'hamlet', 'prince', 'of'): {'occurrence': 1, 'next_words': {'denmark': 1}}\n"
     ]
    }
   ],
   "source": [
    "example_quadgrams = list(quadgrams.items())[:3]  # Show only the first 3 quadgrams\n",
    "for quadgram, details in example_quadgrams:\n",
    "    print(f\"{quadgram}: {details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Count for bigram ('to', 'be', 'or', 'not') is: {'occurrence': 1, 'next_words': {'to': 1}}\n",
      "Example: Count for bigram ('airplane', 'house', 'car', 'dog') is: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Example: Count for bigram ('to', 'be', 'or', 'not') is: {quadgrams.get(('to', 'be', 'or', 'not'))}\")\n",
    "print(f\"Example: Count for bigram ('airplane', 'house', 'car', 'dog') is: {quadgrams.get(('airplane', 'house', 'car', 'dog'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ('to', 'be', 'or', 'not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top suggestions: [('to', 1)]\n"
     ]
    }
   ],
   "source": [
    "top_suggestions = from_bigram_to_next_token_counts(tokens, quadgrams)\n",
    "print(f\"Top suggestions: {top_suggestions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top suggestions for token: ('to', 'be', 'or', 'not')\n",
      "are: [('to', 1.0)]\n",
      "With total number of possible words after the bigram of 1\n"
     ]
    }
   ],
   "source": [
    "top_suggestions = from_bigram_to_next_token_probs(tokens, quadgrams)\n",
    "print(f\"Top suggestions for token: {tokens}\\nare: {top_suggestions[1]}\\nWith total number of possible words after the bigram of {top_suggestions[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled next token for bigram ('to', 'be', 'or', 'not'): to\n"
     ]
    }
   ],
   "source": [
    "next_token = sample_next_token(tokens, quadgrams)\n",
    "print(f\"Sampled next token for bigram {tokens}: {next_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text from bigram ('to', 'be', 'or', 'not'):\n",
      "to be or not to be that is the question whether tis nobler in the mind to suffer the slings and arrows of outrageous\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text_from_bigram(tokens, quadgrams, max_length=20)\n",
    "print(f\"Generated text from bigram {tokens}:\\n{' '.join(generated_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = 'to be or not to be that is the question whether tis nobler in the mind to suffer the slings and arrows of outrageous fortune or to take arms against a sea of troubles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(goal, generated_text):\n",
    "    goal_words = goal.split()\n",
    "    generated_words = generated_text[:len(goal_words)]\n",
    "    correct = sum([1 for goal_word, generated_word in zip(goal_words, generated_words) if goal_word == generated_word])\n",
    "    return correct / len(goal_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text from bigram ('to', 'be'):\n",
      "to be a villain kills my father s leave what says polonius lord polonius i would not this sir and therefore i forbid my tears but yet i hold my peace i\n",
      "Accuracy: 0.058823529411764705\n",
      "\n",
      "Generated text from trigram ('to', 'be', 'or'):\n",
      "to be or not to crack the wind of me as if you would drive me into a towering passion horatio peace who comes here enter osric osric your lordship speaks most infallibly\n",
      "Accuracy: 0.14705882352941177\n",
      "\n",
      "Generated text from quadgram ('to', 'be', 'or', 'not'):\n",
      "to be or not to be that is the question whether tis nobler in the mind to suffer the slings and arrows of outrageous fortune or to take arms against a sea of troubles\n",
      "Accuracy: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_grams():\n",
    "    bigram_input = ('to','be')\n",
    "    generated_text = generate_text_from_bigram(bigram_input, bigrams, max_length=30)\n",
    "    print(f\"Generated text from bigram {bigram_input}:\\n{' '.join(generated_text)}\")\n",
    "    print(f\"Accuracy: {accuracy(goal, generated_text)}\")\n",
    "    print()\n",
    "\n",
    "    trigram_input = ('to','be','or')\n",
    "    generated_text = generate_text_from_bigram(trigram_input, trigrams, max_length=30)\n",
    "    print(f\"Generated text from trigram {trigram_input}:\\n{' '.join(generated_text)}\")\n",
    "    print(f\"Accuracy: {accuracy(goal, generated_text)}\")\n",
    "    print()\n",
    "\n",
    "    quadgram_input = ('to','be','or','not')\n",
    "    generated_text = generate_text_from_bigram(quadgram_input, quadgrams, max_length=30)\n",
    "    print(f\"Generated text from quadgram {quadgram_input}:\\n{' '.join(generated_text)}\")\n",
    "    print(f\"Accuracy: {accuracy(goal, generated_text)}\")\n",
    "    print()\n",
    "test_grams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_feedback():\n",
    "    print(\"We will find text in Hamlet the famus play by William Shakespeare\")\n",
    "    print(\"The code will ask you to start a sentence with 2/3/4 words and I will complete the sentence\")\n",
    "    print('lets start')\n",
    "\n",
    "    bigram_input = input(\"Please enter the first TWO words of the sentence that Shakespeare will complete:\\n\")\n",
    "    # make a list out of the input\n",
    "    bigram_input = bigram_input.split()\n",
    "    bigram_input = tuple(bigram_input)\n",
    "    generated_text = generate_text_from_bigram(bigram_input, bigrams, max_length=30)\n",
    "    print(f\"-------------\\nGenerated text from digital Shakespeare:\\n{' '.join(generated_text)}\\n\")\n",
    "    feedback_bigram = input(\"Did Shakespeare complete the sentence correctly? How do you feel about this digital poet? Does it resemble the master?\\n\")\n",
    "\n",
    "    trigram_input = input(\"Please enter the first THREE words of the sentence that Shakespeare will complete:\\n\")\n",
    "    trigram_input = trigram_input.split()\n",
    "    trigram_input = tuple(trigram_input)\n",
    "    generated_text = generate_text_from_bigram(trigram_input, trigrams, max_length=30)\n",
    "    print(f\"-------------\\nGenerated text from digital Shakespeare:\\n{' '.join(generated_text)}\\n\")\n",
    "    feedback_trigram = input(\"Did Shakespeare complete the sentence correctly? How do you feel about this digital poet? Does it resemble the master?\\n\")\n",
    "\n",
    "    quadgram_input = input(\"Please enter the first FOUR words of the sentence that Shakespeare will complete:\\n\")\n",
    "    quadgram_input = quadgram_input.split()\n",
    "    quadgram_input = tuple(quadgram_input)\n",
    "    generated_text = generate_text_from_bigram(quadgram_input, quadgrams, max_length=30)\n",
    "    print(f\"-------------\\nGenerated text from digital Shakespeare:\\n{' '.join(generated_text)}\\n\")\n",
    "    feedback_quadgram = input(\"Did Shakespeare complete the sentence correctly? How do you feel about this digital poet? Does it resemble the master?\\n\")\n",
    "\n",
    "    feedbacks = [feedback_bigram, feedback_trigram, feedback_quadgram]\n",
    "    return feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will find text in Hamlet the famus play by William Shakespeare\n",
      "The code will ask you to start a sentence with 2/3/4 words and I will complete the sentence\n",
      "lets start\n",
      "-------------\n",
      "Generated text from digital Shakespeare:\n",
      "to be a couch for luxury and damned light to their graves like beds fight for a state but to the king s ears hamlet he was mad he shall sir an\n",
      "\n",
      "-------------\n",
      "Generated text from digital Shakespeare:\n",
      "to be or not to crack the wind of the poor phrase running it thus you ll tender me a fool ophelia my lord he s going to his mother s closet behind\n",
      "\n",
      "-------------\n",
      "Generated text from digital Shakespeare:\n",
      "to be or not to be that is the question whether tis nobler in the mind to suffer the slings and arrows of outrageous fortune or to take arms against a sea of troubles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feedbacks = gather_feedback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My roomate tested the digital poet.And I ask him to give me feedbacks\n",
      "\n",
      "-------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"this is not even close to what I was expecting! This digital poet is not starting well... As I thought... machine can't replace and not even e√¨imitate humans\",\n",
       " 'Mmmmh it started good, but then it start pasting random words... Gringo what is this ?!?!',\n",
       " 'Wow!! This are the exact words I was expecting... but still... everyone can find the test and start reading it... ']"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('My roomate tested the digital poet.And I ask him to give me feedbacks\\n\\n-------------')\n",
    "feedbacks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
